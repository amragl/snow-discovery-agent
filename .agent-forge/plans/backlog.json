{
  "project": "snow-discovery-agent",
  "updated_at": "2026-02-12T22:00:00Z",
  "phases": [
    {
      "id": "phase-1",
      "name": "Foundation",
      "description": "Project structure, ServiceNow REST client, FastMCP server skeleton, configuration management, and base models. Establishes the core infrastructure every subsequent phase builds upon.",
      "milestone": "MCP server starts, connects to ServiceNow instance, and responds to a health-check tool call with real instance metadata",
      "status": "completed",
      "tickets": ["DISC-001", "DISC-002", "DISC-003", "DISC-004", "DISC-005", "DISC-006"]
    },
    {
      "id": "phase-2",
      "name": "Core Discovery Tools",
      "description": "Implement the primary MCP tools for discovery operations: scheduling scans, checking status, managing credentials, and managing IP ranges. These are the bread-and-butter operations every ServiceNow Discovery admin needs.",
      "milestone": "All four core discovery tools (schedule_discovery_scan, get_discovery_status, list_discovery_schedules, manage_discovery_ranges) are functional with real ServiceNow REST API calls",
      "status": "planned",
      "tickets": ["DISC-007", "DISC-008", "DISC-009", "DISC-010", "DISC-011"]
    },
    {
      "id": "phase-3",
      "name": "Analysis and Remediation",
      "description": "Advanced tools for analyzing discovery scan results, remediating common failures, managing CI classification patterns, computing discovery health metrics, and comparing discovery runs over time.",
      "milestone": "analyze_discovery_results, remediate_discovery_failures, get_discovery_patterns, get_discovery_health, and compare_discovery_runs tools are operational against real ServiceNow data",
      "status": "planned",
      "tickets": ["DISC-012", "DISC-013", "DISC-014", "DISC-015", "DISC-016"]
    },
    {
      "id": "phase-4",
      "name": "Testing",
      "description": "Comprehensive test suite covering unit tests for every module, integration tests against a real ServiceNow instance, and end-to-end MCP protocol tests. Target: at least 80% code coverage.",
      "milestone": "Test suite passes with at least 80% code coverage; integration tests confirm every MCP tool works against a real ServiceNow instance",
      "status": "planned",
      "tickets": ["DISC-017", "DISC-018", "DISC-019", "DISC-020"]
    },
    {
      "id": "phase-5",
      "name": "Documentation and Deployment",
      "description": "Production-ready README, API reference docs, Docker containerization, CI/CD pipeline, and release packaging. Makes the project deployable and maintainable.",
      "milestone": "Project is fully documented, containerized with Docker, has a working CI/CD pipeline, and can be installed via pip or run as a container",
      "status": "planned",
      "tickets": ["DISC-021", "DISC-022", "DISC-023", "DISC-024", "DISC-025"]
    }
  ],
  "tickets": [
    {
      "id": "DISC-001",
      "github_issue": 1,
      "title": "Initialize Python project structure with pyproject.toml and package layout",
      "description": "Create the foundational Python project structure following the servicenow-cmdb-mcp reference architecture. This includes:\n\n- pyproject.toml with project metadata, dependencies (fastmcp, pydantic, requests, python-dotenv), dev dependencies (pytest, pytest-cov, ruff, mypy), and entry points\n- src/snow_discovery_agent/ package directory with __init__.py\n- tests/ directory with __init__.py and conftest.py\n- .env.example with SERVICENOW_INSTANCE, SERVICENOW_USERNAME, SERVICENOW_PASSWORD placeholders\n- .gitignore for Python projects (venv, __pycache__, .env, dist, etc.)\n- .python-version file specifying 3.11+\n\nAcceptance criteria:\n- Running `pip install -e .` succeeds\n- Package is importable as `snow_discovery_agent`\n- All dev tools (pytest, ruff, mypy) are installable via `pip install -e '.[dev]'`",
      "phase": "phase-1",
      "priority": "critical",
      "type": "feature",
      "status": "done",
      "dependencies": [],
      "assigned_agent": "build",
      "estimated_complexity": "small",
      "pr_number": 2,
      "completed_at": "2026-02-13T18:35:00Z"
    },
    {
      "id": "DISC-002",
      "github_issue": 3,
      "title": "Implement ServiceNow REST client with authentication and error handling",
      "description": "Create a reusable ServiceNow REST client module at src/snow_discovery_agent/client.py that handles all HTTP communication with ServiceNow. This is the foundation every tool uses.\n\nRequirements:\n- ServiceNowClient class with configurable instance URL, username, password\n- Support for basic auth (username/password) via requests library\n- Generic methods: get(), post(), put(), patch(), delete() that wrap requests with proper headers (Accept: application/json, Content-Type: application/json)\n- Automatic URL construction: base_url + '/api/now/table/' + table_name for table API\n- Query parameter support (sysparm_query, sysparm_fields, sysparm_limit, sysparm_offset)\n- Response parsing: extract 'result' from JSON response body\n- Comprehensive error handling: connection errors, auth failures (401), permission denied (403), not found (404), rate limiting (429)\n- Custom ServiceNowError exception hierarchy\n- Request/response logging at DEBUG level\n- Connection timeout configuration (default 30s)\n- Session reuse for connection pooling\n\nAcceptance criteria:\n- Client can authenticate against a real ServiceNow instance\n- GET /api/now/table/sys_properties?sysparm_limit=1 returns data\n- Auth failures raise ServiceNowAuthError\n- Connection timeouts raise ServiceNowConnectionError",
      "phase": "phase-1",
      "priority": "critical",
      "type": "feature",
      "status": "done",
      "dependencies": ["DISC-001"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": 4,
      "completed_at": "2026-02-18T02:15:00Z"
    },
    {
      "id": "DISC-003",
      "github_issue": 5,
      "title": "Define Pydantic models for all ServiceNow Discovery tables",
      "description": "Create Pydantic v2 models at src/snow_discovery_agent/models.py representing the key ServiceNow Discovery tables and their fields.\n\nModels to define:\n- DiscoveryStatus: Maps to discovery_status table (sys_id, name, state, source, dscl_status, log, started, completed, ci_count, ip_address, mid_server)\n- DiscoverySchedule: Maps to discovery_schedule table (sys_id, name, active, discover, max_run_time, run_dayofweek, run_time, mid_select_method, location)\n- DiscoveryCredential: Maps to discovery_credential table (sys_id, name, type, active, tag, order, affinity)\n- DiscoveryRange: Maps to discovery_range table (sys_id, name, type, active, range_start, range_end, include)\n- DiscoveryPattern: Maps to cmdb_ci_pattern table (sys_id, name, active, ci_type, criteria, description)\n- DiscoveryLog: Maps to discovery_log table (sys_id, status, level, message, source, created_on)\n- DiscoveryHealthSummary: Custom model for aggregated health metrics (total_scans, successful, failed, error_rate, avg_duration, top_errors)\n- DiscoveryCompareResult: Custom model for run comparison results\n\nAll models must:\n- Use Pydantic v2 syntax (model_config, field_validator)\n- Handle ServiceNow's datetime format strings\n- Have from_snow() classmethod that creates instance from raw ServiceNow API response dict\n- Have proper field defaults for optional fields\n- Include docstrings\n\nAcceptance criteria:\n- All models validate real ServiceNow API response data without errors\n- from_snow() correctly maps ServiceNow field names to Python attributes\n- Serialization to dict/JSON works correctly",
      "phase": "phase-1",
      "priority": "high",
      "type": "feature",
      "status": "done",
      "dependencies": ["DISC-001"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": 6,
      "completed_at": "2026-02-18T15:30:00Z"
    },
    {
      "id": "DISC-004",
      "github_issue": 7,
      "title": "Implement configuration management with environment variables and validation",
      "description": "Create a configuration module at src/snow_discovery_agent/config.py that manages all application settings.\n\nRequirements:\n- Pydantic Settings class (from pydantic-settings) for type-safe config\n- Load from environment variables with SNOW_ prefix: SNOW_INSTANCE, SNOW_USERNAME, SNOW_PASSWORD\n- Optional settings: SNOW_TIMEOUT (default 30), SNOW_MAX_RESULTS (default 100), SNOW_LOG_LEVEL (default INFO)\n- Validation: instance URL must be valid HTTPS URL, credentials must be non-empty\n- Support for .env file loading via python-dotenv\n- Singleton pattern or factory function get_config() to avoid re-reading env on every call\n- Clear error messages when required config is missing\n\nAcceptance criteria:\n- Config loads from .env file and environment variables\n- Missing required fields raise clear validation errors\n- get_config() returns consistent configuration object\n- Config values are used by ServiceNowClient automatically",
      "phase": "phase-1",
      "priority": "high",
      "type": "feature",
      "status": "done",
      "dependencies": ["DISC-001"],
      "assigned_agent": "build",
      "estimated_complexity": "small",
      "pr_number": 8,
      "completed_at": "2026-02-18T18:00:00Z"
    },
    {
      "id": "DISC-005",
      "github_issue": 9,
      "title": "Create FastMCP server skeleton with tool registration framework",
      "description": "Create the FastMCP server entry point at src/snow_discovery_agent/server.py that initializes the MCP server and provides the framework for registering discovery tools.\n\nRequirements:\n- FastMCP server instance with name 'snow-discovery-agent' and description\n- Server initialization that loads config and creates ServiceNowClient\n- Tool registration pattern using @mcp.tool() decorators\n- A placeholder health-check tool (get_server_info) that returns server version and status\n- Proper server startup with `mcp.run()` for stdio transport\n- Error handling wrapper for all tool calls that catches ServiceNowError and returns structured error responses\n- Logging setup with configurable log level\n- Entry point in pyproject.toml: `snow-discovery-agent = \"snow_discovery_agent.server:main\"`\n\nAcceptance criteria:\n- Server starts without errors when run via `python -m snow_discovery_agent.server`\n- MCP inspector can connect and list the health-check tool\n- Health-check tool returns server metadata\n- Server gracefully handles missing configuration",
      "phase": "phase-1",
      "priority": "critical",
      "type": "feature",
      "status": "done",
      "dependencies": ["DISC-002", "DISC-004"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": 10,
      "completed_at": "2026-02-18T20:30:00Z"
    },
    {
      "id": "DISC-006",
      "github_issue": 11,
      "title": "Implement manage_discovery_credentials tool for credential CRUD operations",
      "description": "Create the manage_discovery_credentials MCP tool at src/snow_discovery_agent/tools/credentials.py for managing ServiceNow Discovery credentials.\n\nServiceNow table: discovery_credential\n\nOperations:\n- LIST: Query discovery_credential table with optional filters (type, active status, tag). Return list of DiscoveryCredential models. Fields: sys_id, name, type, active, tag, order, affinity.\n- GET: Retrieve a single credential by sys_id. Return full DiscoveryCredential.\n- CREATE: Create a new discovery credential. Required fields: name, type. Optional: tag, order, active.\n- UPDATE: Update an existing credential by sys_id. Accept partial updates.\n- DELETE: Delete a credential by sys_id.\n\nSecurity considerations:\n- NEVER return or log credential secrets (passwords, private keys)\n- Only expose metadata fields (name, type, tag, active status)\n- Log credential operations at INFO level for audit trail\n\nAcceptance criteria:\n- All five CRUD operations work against real discovery_credential table\n- Credential secrets are never exposed in responses\n- Invalid sys_id returns proper error message\n- Filtering by type and active status works correctly",
      "phase": "phase-1",
      "priority": "high",
      "type": "feature",
      "status": "done",
      "dependencies": ["DISC-005", "DISC-003"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": 12,
      "completed_at": "2026-02-18T22:30:00Z"
    },
    {
      "id": "DISC-007",
      "github_issue": null,
      "title": "Implement schedule_discovery_scan tool to create and trigger discovery scans",
      "description": "Create the schedule_discovery_scan MCP tool at src/snow_discovery_agent/tools/schedule.py for creating and triggering ServiceNow Discovery scans.\n\nServiceNow tables: discovery_schedule, discovery_status\n\nCapabilities:\n- TRIGGER: Start an immediate discovery scan by activating a schedule or creating an on-demand scan. Use the Discovery REST API or table API to trigger. Set the schedule's 'discover' field to 'Active' to trigger.\n- CREATE_SCHEDULE: Create a new discovery schedule with: name, discover type (IP, CI, etc.), IP ranges, MID server selection, run frequency, max run time.\n- LINK_RANGES: Associate IP ranges with a schedule by updating the discovery_schedule's range reference.\n- LINK_CREDENTIALS: Associate credentials with a schedule.\n\nInput parameters:\n- action: 'trigger' | 'create'\n- For trigger: schedule_sys_id (required)\n- For create: name, discover_type, ip_ranges (list), mid_server (optional), max_run_time (optional, default '02:00:00')\n\nAcceptance criteria:\n- Triggering an existing schedule starts a discovery scan (verified by checking discovery_status)\n- Creating a new schedule produces a valid discovery_schedule record\n- Proper error handling for invalid schedule IDs, missing ranges, inactive schedules",
      "phase": "phase-2",
      "priority": "critical",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-005", "DISC-003"],
      "assigned_agent": "build",
      "estimated_complexity": "large",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-008",
      "github_issue": null,
      "title": "Implement get_discovery_status tool to check scan status and results",
      "description": "Create the get_discovery_status MCP tool at src/snow_discovery_agent/tools/status.py for querying the status and results of discovery scans.\n\nServiceNow table: discovery_status\n\nCapabilities:\n- GET_STATUS: Retrieve the status of a specific discovery scan by sys_id. Return DiscoveryStatus model with: state, source, started/completed timestamps, CI count, IP address, MID server, log summary.\n- LIST_RECENT: List recent discovery scans with optional filters: state (Active, Completed, Cancelled, Error), source schedule, date range, limit (default 20).\n- GET_DETAILS: For a specific scan, retrieve detailed results including: CIs discovered, errors encountered, duration, IP addresses scanned.\n- POLL: Check if a scan has completed (for use after trigger). Return current state and estimated completion.\n\nInput parameters:\n- action: 'get' | 'list' | 'details' | 'poll'\n- For get/details/poll: scan_sys_id (required)\n- For list: state (optional), limit (optional), date_from (optional), date_to (optional)\n\nAcceptance criteria:\n- Can retrieve status of a real completed discovery scan\n- List returns scans sorted by most recent first\n- State values correctly map to ServiceNow discovery states\n- Poll correctly detects scan completion",
      "phase": "phase-2",
      "priority": "critical",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-005", "DISC-003"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-009",
      "github_issue": null,
      "title": "Implement list_discovery_schedules tool for viewing configured schedules",
      "description": "Create the list_discovery_schedules MCP tool at src/snow_discovery_agent/tools/schedules_list.py for listing and viewing discovery schedule configurations.\n\nServiceNow table: discovery_schedule\n\nCapabilities:\n- LIST: Query all discovery schedules with optional filters: active status, discover type, name pattern. Return list of DiscoverySchedule models.\n- GET: Retrieve a single schedule by sys_id with full details including associated ranges, credentials, and MID server configuration.\n- SUMMARY: Return a summary view showing: total schedules, active vs inactive, next run times, last run results.\n\nInput parameters:\n- action: 'list' | 'get' | 'summary'\n- For list: active (optional bool), discover_type (optional), name_filter (optional), limit (optional)\n- For get: schedule_sys_id (required)\n\nAcceptance criteria:\n- List returns all discovery schedules from a real instance\n- Active/inactive filtering works correctly\n- Get returns full schedule details including related records\n- Summary provides accurate counts",
      "phase": "phase-2",
      "priority": "high",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-005", "DISC-003"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-010",
      "github_issue": null,
      "title": "Implement manage_discovery_ranges tool for IP range CRUD operations",
      "description": "Create the manage_discovery_ranges MCP tool at src/snow_discovery_agent/tools/ranges.py for managing ServiceNow Discovery IP ranges and networks.\n\nServiceNow table: discovery_range\n\nOperations:\n- LIST: Query discovery_range table with optional filters (type, active, name pattern). Return list of DiscoveryRange models.\n- GET: Retrieve a single range by sys_id.\n- CREATE: Create a new discovery range. Required: name, type ('IP Range', 'IP Network', 'IP Address'). For IP Range: range_start, range_end. For IP Network: range_start (network CIDR). For IP Address: range_start (single IP).\n- UPDATE: Update an existing range by sys_id.\n- DELETE: Delete a range by sys_id.\n- VALIDATE: Validate that an IP range/network is syntactically correct before creating.\n\nInput validation:\n- IP addresses must be valid IPv4 or IPv6\n- Range end must be >= range start for IP Range type\n- CIDR notation must be valid for IP Network type\n- Prevent overlapping ranges (warn, do not block)\n\nAcceptance criteria:\n- All CRUD operations work against real discovery_range table\n- IP validation catches malformed addresses\n- Range type determines which fields are required\n- Overlap detection warns about existing ranges that cover same IPs",
      "phase": "phase-2",
      "priority": "high",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-005", "DISC-003"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-011",
      "github_issue": null,
      "title": "Create tools package structure with shared utilities and error handling",
      "description": "Create the tools package at src/snow_discovery_agent/tools/__init__.py with shared utilities used across all tool modules.\n\nRequirements:\n- tools/__init__.py that exports all tool registration functions\n- tools/utils.py with shared helpers:\n  - format_snow_datetime(): Convert ServiceNow datetime strings to ISO 8601\n  - build_query(): Build sysparm_query strings from filter dicts\n  - paginate(): Handle ServiceNow pagination (sysparm_offset, sysparm_limit)\n  - validate_sys_id(): Check if a string is a valid ServiceNow sys_id format (32-char hex)\n  - truncate_description(): Safely truncate long text fields for display\n- tools/errors.py with tool-specific error types:\n  - ToolError base class with error_code and message\n  - InvalidParameterError, RecordNotFoundError, PermissionError\n- Consistent response format for all tools: {\"success\": bool, \"data\": ..., \"message\": str, \"error\": str|null}\n\nAcceptance criteria:\n- All utility functions have docstrings and type hints\n- build_query correctly handles AND/OR conditions, encoded queries\n- paginate handles ServiceNow's X-Total-Count header\n- Response format is consistent across all tools",
      "phase": "phase-2",
      "priority": "high",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-005"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-012",
      "github_issue": null,
      "title": "Implement analyze_discovery_results tool for scan result analysis",
      "description": "Create the analyze_discovery_results MCP tool at src/snow_discovery_agent/tools/analysis.py for analyzing discovery scan results and identifying patterns.\n\nServiceNow tables: discovery_status, discovery_log\n\nCapabilities:\n- ANALYZE_SCAN: For a given scan sys_id, analyze the results: total CIs discovered, new CIs vs updated CIs, errors and warnings from discovery_log, scan duration, IP coverage.\n- ERROR_ANALYSIS: Parse discovery_log entries for a scan to categorize errors: credential failures, network timeouts, classification failures, port scan failures. Group by error type with counts.\n- TREND_ANALYSIS: Analyze results across multiple scans (last N scans or date range) to identify trends: improving/degrading success rate, recurring errors, CI count changes over time.\n- COVERAGE_ANALYSIS: Compare discovered IPs against configured ranges to compute coverage percentage and identify gaps.\n\nInput parameters:\n- action: 'analyze' | 'errors' | 'trend' | 'coverage'\n- For analyze/errors: scan_sys_id (required)\n- For trend: schedule_sys_id (optional), last_n_scans (optional, default 10), date_from/date_to (optional)\n- For coverage: schedule_sys_id (required)\n\nAcceptance criteria:\n- Analyze returns accurate CI counts from real scan data\n- Error categorization correctly groups discovery_log entries\n- Trend analysis shows meaningful patterns across multiple scans\n- Coverage analysis identifies IPs in range but not discovered",
      "phase": "phase-3",
      "priority": "critical",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-008", "DISC-011"],
      "assigned_agent": "build",
      "estimated_complexity": "large",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-013",
      "github_issue": null,
      "title": "Implement remediate_discovery_failures tool for automated failure resolution",
      "description": "Create the remediate_discovery_failures MCP tool at src/snow_discovery_agent/tools/remediation.py for diagnosing and fixing common discovery failures.\n\nServiceNow tables: discovery_status, discovery_log, discovery_credential, discovery_range\n\nRemediaton capabilities:\n- DIAGNOSE: Given a scan sys_id, analyze failures and return a structured diagnosis: root cause category, affected IPs/CIs, suggested remediation steps.\n- CREDENTIAL_FIX: When failures are credential-related, check if the credential is active, test connectivity, suggest credential rotation or re-ordering.\n- NETWORK_FIX: When failures are network-related, verify IP ranges are correct, check for firewall indicators, suggest range adjustments.\n- CLASSIFICATION_FIX: When CIs fail classification, check pattern matches, suggest pattern updates or new patterns.\n- BULK_REMEDIATE: Apply a remediation action to multiple failed items at once (e.g., re-run discovery for all failed IPs).\n\nInput parameters:\n- action: 'diagnose' | 'credential_fix' | 'network_fix' | 'classification_fix' | 'bulk_remediate'\n- scan_sys_id: required for all actions\n- For bulk_remediate: remediation_type, target_items (list of IPs or CI sys_ids)\n\nSafety:\n- NEVER automatically modify credentials without explicit confirmation\n- Log all remediation actions at INFO level\n- Return a dry-run plan before executing any changes\n\nAcceptance criteria:\n- Diagnose correctly categorizes real discovery failures\n- Credential fix identifies inactive or misconfigured credentials\n- Network fix detects range misconfigurations\n- Bulk remediate generates correct remediation plan",
      "phase": "phase-3",
      "priority": "high",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-012", "DISC-006"],
      "assigned_agent": "build",
      "estimated_complexity": "xl",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-014",
      "github_issue": null,
      "title": "Implement get_discovery_patterns tool for CI classification pattern management",
      "description": "Create the get_discovery_patterns MCP tool at src/snow_discovery_agent/tools/patterns.py for listing and managing CI classification patterns.\n\nServiceNow table: cmdb_ci_pattern\n\nCapabilities:\n- LIST: Query cmdb_ci_pattern table with optional filters: active status, CI type, name pattern. Return list of DiscoveryPattern models.\n- GET: Retrieve a single pattern by sys_id with full criteria details.\n- ANALYZE: For a given CI type, show all patterns that could match it, ordered by priority. Identify potential conflicts between patterns.\n- COVERAGE: Show which CI types have patterns defined and which are missing coverage.\n\nInput parameters:\n- action: 'list' | 'get' | 'analyze' | 'coverage'\n- For list: active (optional), ci_type (optional), name_filter (optional), limit (optional)\n- For get: pattern_sys_id (required)\n- For analyze: ci_type (required)\n\nAcceptance criteria:\n- List returns real patterns from cmdb_ci_pattern table\n- Analyze correctly identifies pattern priority and conflicts\n- Coverage report shows CI types with and without patterns\n- All patterns include their classification criteria",
      "phase": "phase-3",
      "priority": "medium",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-005", "DISC-003", "DISC-011"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-015",
      "github_issue": null,
      "title": "Implement get_discovery_health tool for overall discovery health metrics",
      "description": "Create the get_discovery_health MCP tool at src/snow_discovery_agent/tools/health.py for computing overall ServiceNow Discovery health metrics.\n\nServiceNow tables: discovery_status, discovery_schedule, discovery_credential, discovery_range, discovery_log\n\nMetrics to compute:\n- Scan health: total scans (last 7/30 days), success rate, average duration, error rate trend\n- Schedule health: total schedules, active vs inactive, schedules with no recent runs, schedules with high failure rates\n- Credential health: total credentials, active vs inactive, credentials with recent auth failures\n- Range health: total ranges, active vs inactive, ranges with no discoveries, overlapping ranges\n- Overall health score: 0-100 composite score based on weighted metrics\n\nOutput format:\n- DiscoveryHealthSummary model with all computed metrics\n- Color-coded status indicators: healthy (>80), warning (50-80), critical (<50)\n- List of actionable recommendations based on health findings\n\nInput parameters:\n- period: 'day' | 'week' | 'month' (default 'week')\n- include_recommendations: bool (default true)\n\nAcceptance criteria:\n- Health score computed from real ServiceNow data\n- Each sub-metric (scan, schedule, credential, range) is individually accurate\n- Recommendations are specific and actionable\n- Period parameter correctly scopes the analysis window",
      "phase": "phase-3",
      "priority": "high",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-008", "DISC-009", "DISC-006", "DISC-010"],
      "assigned_agent": "build",
      "estimated_complexity": "large",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-016",
      "github_issue": null,
      "title": "Implement compare_discovery_runs tool to diff two scan results",
      "description": "Create the compare_discovery_runs MCP tool at src/snow_discovery_agent/tools/compare.py for comparing the results of two discovery scans.\n\nServiceNow tables: discovery_status, discovery_log\n\nCapabilities:\n- COMPARE: Given two scan sys_ids, produce a detailed comparison:\n  - CIs found in scan A but not scan B (lost CIs)\n  - CIs found in scan B but not scan A (new CIs)\n  - CIs found in both with changed attributes\n  - Error comparison: new errors, resolved errors, persistent errors\n  - Duration and performance comparison\n  - IP coverage comparison\n- COMPARE_SEQUENTIAL: Compare the last N scans for a given schedule to show progression over time. Return a timeline of changes.\n\nOutput format:\n- DiscoveryCompareResult model with added/removed/changed/errors sections\n- Summary statistics: delta_ci_count, delta_error_count, delta_duration\n- Visual-friendly diff format suitable for LLM consumption\n\nInput parameters:\n- action: 'compare' | 'sequential'\n- For compare: scan_a_sys_id, scan_b_sys_id\n- For sequential: schedule_sys_id, last_n (default 5)\n\nAcceptance criteria:\n- Comparison correctly identifies new, lost, and changed CIs between two real scans\n- Sequential comparison shows meaningful trends\n- Performance metrics are accurately computed\n- Large result sets are paginated or summarized",
      "phase": "phase-3",
      "priority": "medium",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-008", "DISC-011"],
      "assigned_agent": "build",
      "estimated_complexity": "large",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-017",
      "github_issue": null,
      "title": "Write unit tests for ServiceNow client, config, and models modules",
      "description": "Create comprehensive unit tests for the foundation modules.\n\nTest files:\n- tests/test_client.py: Test ServiceNowClient methods, URL construction, query building, error handling, timeout behavior, session management. Test that auth headers are set correctly. Test response parsing extracts 'result' key.\n- tests/test_config.py: Test config loading from env vars, .env file, defaults, validation errors for missing required fields, URL format validation.\n- tests/test_models.py: Test all Pydantic models with real ServiceNow response fixtures. Test from_snow() classmethod, serialization, field validation, optional field defaults, datetime parsing.\n\nRequirements:\n- Use pytest with parametrize for multiple scenarios\n- Store test fixtures in tests/fixtures/ as JSON files (real ServiceNow response formats)\n- NO MOCKS of the ServiceNow API itself -- test the parsing/validation logic with real response structures\n- Test error cases: malformed responses, missing fields, invalid types\n\nAcceptance criteria:\n- All tests pass with `pytest tests/test_client.py tests/test_config.py tests/test_models.py`\n- At least 90% coverage for client.py, config.py, models.py\n- Fixtures contain realistic ServiceNow response data",
      "phase": "phase-4",
      "priority": "high",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-002", "DISC-003", "DISC-004"],
      "assigned_agent": "build",
      "estimated_complexity": "large",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-018",
      "github_issue": null,
      "title": "Write unit tests for all MCP tool modules",
      "description": "Create unit tests for every tool in the tools/ package.\n\nTest files:\n- tests/test_tools_credentials.py: Test credential CRUD operations, security filtering (no secrets in output), input validation.\n- tests/test_tools_schedule.py: Test scan triggering logic, schedule creation validation, range linking.\n- tests/test_tools_status.py: Test status retrieval, list filtering, poll logic.\n- tests/test_tools_schedules_list.py: Test schedule listing, summary computation.\n- tests/test_tools_ranges.py: Test range CRUD, IP validation, overlap detection, CIDR parsing.\n- tests/test_tools_analysis.py: Test error categorization logic, trend computation, coverage calculation.\n- tests/test_tools_remediation.py: Test diagnosis logic, remediation plan generation, safety checks.\n- tests/test_tools_patterns.py: Test pattern listing, conflict detection, coverage analysis.\n- tests/test_tools_health.py: Test health score computation, metric aggregation, recommendation generation.\n- tests/test_tools_compare.py: Test CI diff logic, sequential comparison, summary stats.\n- tests/test_tools_utils.py: Test all shared utilities.\n\nRequirements:\n- Each tool module must have its own test file\n- Test the business logic (parsing, computation, validation) using real response fixtures\n- Test error handling paths\n- Test input parameter validation\n\nAcceptance criteria:\n- All tool tests pass\n- Combined tool test coverage is at least 80%\n- Each tool has tests for success and error paths",
      "phase": "phase-4",
      "priority": "high",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-006", "DISC-007", "DISC-008", "DISC-009", "DISC-010", "DISC-011", "DISC-012", "DISC-013", "DISC-014", "DISC-015", "DISC-016"],
      "assigned_agent": "build",
      "estimated_complexity": "xl",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-019",
      "github_issue": null,
      "title": "Write integration tests that verify all tools against a real ServiceNow instance",
      "description": "Create integration tests that exercise the full stack: MCP tool -> ServiceNow client -> real ServiceNow API.\n\nTest file: tests/integration/test_integration.py\n\nTests to write:\n- test_client_connectivity: Verify client can connect and authenticate\n- test_list_schedules: Call list_discovery_schedules and verify response structure\n- test_get_status: Retrieve a real discovery status record\n- test_list_credentials: List credentials and verify no secrets in response\n- test_list_ranges: List discovery ranges and verify IP format\n- test_list_patterns: List CI patterns and verify structure\n- test_health_check: Call get_discovery_health and verify score is 0-100\n- test_full_workflow: Trigger a scan (if safe), poll status, analyze results\n\nRequirements:\n- Tests require SNOW_INSTANCE, SNOW_USERNAME, SNOW_PASSWORD env vars\n- Mark all integration tests with @pytest.mark.integration\n- Skip gracefully if ServiceNow credentials are not configured\n- Use pytest-timeout to prevent hanging on network issues (60s per test)\n- NEVER create or delete production data -- only read operations, or use a dev/test instance\n\nAcceptance criteria:\n- Integration tests pass against a real ServiceNow instance\n- All tests are skippable when no credentials are configured\n- No test creates or destroys production data without explicit markers",
      "phase": "phase-4",
      "priority": "medium",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-017", "DISC-018"],
      "assigned_agent": "build",
      "estimated_complexity": "large",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-020",
      "github_issue": null,
      "title": "Achieve at least 80% overall test coverage with pytest-cov reporting",
      "description": "Ensure the project achieves at least 80% code coverage across all modules and configure coverage reporting.\n\nRequirements:\n- Add pytest-cov to dev dependencies\n- Configure pyproject.toml with [tool.pytest.ini_options] and [tool.coverage] sections\n- Coverage source: src/snow_discovery_agent/\n- Coverage exclusions: __init__.py, server startup code, type checking blocks\n- Generate both terminal and HTML coverage reports\n- Add coverage badge configuration for README\n- Identify and fill any coverage gaps from DISC-017 and DISC-018\n- Write additional tests if any module is below 80%\n\nAcceptance criteria:\n- `pytest --cov=snow_discovery_agent --cov-report=term-missing` shows >= 80% overall\n- No individual module is below 70% coverage\n- Coverage configuration is in pyproject.toml\n- HTML report is generated to htmlcov/",
      "phase": "phase-4",
      "priority": "medium",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-017", "DISC-018"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-021",
      "github_issue": null,
      "title": "Write comprehensive README with installation, configuration, and usage docs",
      "description": "Replace the placeholder README.md with a comprehensive project README.\n\nSections:\n- Project title and badges (CI status, coverage, Python version, license)\n- Overview: What snow-discovery-agent does, how it fits in the ServiceNow Suite\n- Features list: All 10+ MCP tools with one-line descriptions\n- Architecture diagram: FastMCP server -> ServiceNow REST API -> Discovery tables\n- Prerequisites: Python 3.11+, ServiceNow instance with Discovery plugin, required roles (discovery_admin)\n- Installation: pip install, from source, development setup\n- Configuration: All environment variables with descriptions and defaults\n- Quick Start: Step-by-step getting started guide with example commands\n- Tool Reference: Each tool with parameters, example input/output, and notes\n- Integration: How to use with Claude Desktop, MCP Inspector, other MCP clients\n- Dependency: How this relates to servicenow-cmdb-mcp\n- Development: How to run tests, linting, type checking\n- Troubleshooting: Common issues and solutions\n- License\n\nAcceptance criteria:\n- README is complete, accurate, and follows the servicenow-cmdb-mcp README structure\n- All tools are documented with example usage\n- Installation instructions work from scratch\n- No placeholder or TODO sections remain",
      "phase": "phase-5",
      "priority": "high",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-016"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-022",
      "github_issue": null,
      "title": "Create Dockerfile and docker-compose for containerized deployment",
      "description": "Create Docker configuration for running the discovery agent as a container.\n\nFiles to create:\n- Dockerfile: Multi-stage build. Stage 1: install dependencies. Stage 2: copy source, set entry point. Base image: python:3.11-slim. Non-root user. Health check.\n- docker-compose.yml: Service definition with environment variable passthrough for SNOW_* vars, volume mount for .env file, restart policy.\n- .dockerignore: Exclude .git, .agent-forge, __pycache__, tests, docs, .env\n\nRequirements:\n- Image size under 200MB\n- Non-root user (appuser)\n- HEALTHCHECK instruction that verifies the MCP server responds\n- Environment variables passed through (not baked in)\n- Support for both stdio and SSE transport modes\n- Build arg for selecting transport mode\n\nAcceptance criteria:\n- `docker build -t snow-discovery-agent .` succeeds\n- `docker run --env-file .env snow-discovery-agent` starts the MCP server\n- Container runs as non-root user\n- Image size is under 200MB\n- Health check passes when server is running",
      "phase": "phase-5",
      "priority": "medium",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-005"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-023",
      "github_issue": null,
      "title": "Set up GitHub Actions CI/CD pipeline with lint, type check, and test stages",
      "description": "Create a GitHub Actions workflow for continuous integration.\n\nFile: .github/workflows/ci.yml\n\nWorkflow stages:\n1. Lint: Run ruff check on all Python files. Fail on any violation.\n2. Type check: Run mypy on src/ with strict mode. Fail on errors.\n3. Unit tests: Run pytest (excluding integration tests) with coverage. Fail if coverage < 80%.\n4. Integration tests: Run only on manual trigger or schedule (not on every PR). Requires ServiceNow secrets.\n5. Build: Verify `pip install .` succeeds. Verify Docker build succeeds.\n\nConfiguration:\n- Trigger on: push to main, pull_request to main\n- Python version matrix: 3.11, 3.12\n- Cache pip dependencies for speed\n- Upload coverage report as artifact\n- GitHub secrets for integration tests: SNOW_INSTANCE, SNOW_USERNAME, SNOW_PASSWORD\n\nAcceptance criteria:\n- CI runs on every PR to main\n- All stages pass for the current codebase\n- Integration tests run on schedule (weekly) or manual trigger only\n- Coverage report is uploaded as artifact\n- Failed lint or type errors block merge",
      "phase": "phase-5",
      "priority": "medium",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-020"],
      "assigned_agent": "build",
      "estimated_complexity": "medium",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-024",
      "github_issue": null,
      "title": "Add ruff linting and mypy type checking configuration",
      "description": "Configure code quality tools for the project.\n\nChanges to pyproject.toml:\n- [tool.ruff]: target-version = 'py311', line-length = 100, select rules (E, F, W, I, N, UP, B, SIM, RUF), ignore rules as needed\n- [tool.ruff.lint.isort]: known-first-party = ['snow_discovery_agent']\n- [tool.mypy]: python_version = '3.11', strict = true, warn_return_any = true, warn_unused_configs = true, plugins = ['pydantic.mypy']\n- [tool.mypy.plugins.pydantic-mypy]: init_forbid_extra = true, init_typed = true\n\nFiles to create:\n- py.typed marker file in src/snow_discovery_agent/ (PEP 561)\n\nRequirements:\n- All existing code must pass ruff check with zero violations\n- All existing code must pass mypy with zero errors (or documented type: ignore comments)\n- Fix any existing violations before configuring\n\nAcceptance criteria:\n- `ruff check src/ tests/` exits with code 0\n- `mypy src/` exits with code 0\n- Configuration is in pyproject.toml (not separate config files)\n- py.typed marker exists",
      "phase": "phase-5",
      "priority": "medium",
      "type": "tech-debt",
      "status": "planned",
      "dependencies": ["DISC-016"],
      "assigned_agent": "build",
      "estimated_complexity": "small",
      "pr_number": null,
      "completed_at": null
    },
    {
      "id": "DISC-025",
      "github_issue": null,
      "title": "Create Claude Desktop MCP integration config and usage examples",
      "description": "Create configuration and documentation for integrating the discovery agent with Claude Desktop and other MCP clients.\n\nFiles to create:\n- claude_desktop_config.json: Example Claude Desktop MCP server configuration pointing to this agent\n- examples/: Directory with example MCP tool call payloads and expected responses\n  - examples/schedule_scan.json\n  - examples/check_status.json\n  - examples/analyze_results.json\n  - examples/health_check.json\n  - examples/compare_runs.json\n\nDocumentation additions to README:\n- Section on Claude Desktop integration with step-by-step setup\n- Section on using with MCP Inspector for testing\n- Section on using with other MCP-compatible clients\n\nRequirements:\n- Config examples must be valid JSON\n- Example payloads must match actual tool input schemas\n- Include both stdio and SSE transport configurations\n\nAcceptance criteria:\n- Claude Desktop can connect to the agent using the example config\n- All example payloads are valid and documented\n- MCP Inspector can list and invoke all tools\n- Both transport modes are documented",
      "phase": "phase-5",
      "priority": "low",
      "type": "feature",
      "status": "planned",
      "dependencies": ["DISC-021"],
      "assigned_agent": "build",
      "estimated_complexity": "small",
      "pr_number": null,
      "completed_at": null
    }
  ]
}
